# GhostGuide Flow Documentation

## Table of Contents

1. [Overview](#overview)
2. [Application Startup Flow](#application-startup-flow)
3. [Session Management Flows](#session-management-flows)
4. [Screenshot Analysis Flow](#screenshot-analysis-flow)
5. [Audio Recording Flow](#audio-recording-flow)
6. [RAG Knowledge Base Flow](#rag-knowledge-base-flow)
7. [Chat Interaction Flow](#chat-interaction-flow)
8. [Configuration Flow](#configuration-flow)
9. [Error Handling Flow](#error-handling-flow)
10. [Data Persistence Flow](#data-persistence-flow)

---

## Overview

This document details all data flows and function call sequences in the GhostGuide application. Each flow shows the exact sequence of method calls, data transformations, and inter-service communications.

**Legend:**
- `â†’` Function call or data flow
- `âš¡` Async operation  
- `ğŸ”„` Loop or iteration
- `â“` Conditional branch
- `âš ï¸` Error handling
- `ğŸ“` Data transformation
- `ğŸ’¾` Data persistence
- `ğŸ¯` IPC communication

---

## Application Startup Flow

### 1. Main Process Initialization

```
main.ts
â”œâ”€â”€ ApplicationController constructor({debug, stealthMode, logLevel})
â”‚   â”œâ”€â”€ this.config = {stealthMode: true, debug: false, ...config}
â”‚   â”œâ”€â”€ this.store = new Store()
â”‚   â”œâ”€â”€ initializeLogging()
â”‚   â”‚   â”œâ”€â”€ app.getPath('userData') â†’ logsDir
â”‚   â”‚   â”œâ”€â”€ fs.mkdirSync(logsDir, {recursive: true})
â”‚   â”‚   â””â”€â”€ this.logFilePath = path.join(logsDir, filename)
â”‚   â”œâ”€â”€ initializeServices()
â”‚   â”‚   â”œâ”€â”€ this.services = {
â”‚   â”‚   â”‚   ocrService: new OCRService(),
â”‚   â”‚   â”‚   captureService: new CaptureService(),
â”‚   â”‚   â”‚   audioService: new AudioService(),
â”‚   â”‚   â”‚   ragService: new RAGService(),
â”‚   â”‚   â”‚   globalRagService: new GlobalRAGService(),
â”‚   â”‚   â”‚   configurationManager: new ConfigurationManager(),
â”‚   â”‚   â”‚   promptLibraryService: new PromptLibraryService(),
â”‚   â”‚   â”‚   sessionManager: new SessionManager(),
â”‚   â”‚   â”‚   windowManager: new WindowManager(),
â”‚   â”‚   â”‚   chatService: new ChatService(deps...)
â”‚   â”‚   â”‚   }
â”‚   â”‚   â”œâ”€â”€ promptLibraryService.setConfigurationManager(configManager)
â”‚   â”‚   â””â”€â”€ chatService = new ChatService(actualDependencies)
â”‚   â””â”€â”€ setupApplicationEvents()
â”‚       â”œâ”€â”€ app.whenReady() â†’ this.initialize()
â”‚       â”œâ”€â”€ app.on('window-all-closed') â†’ this.shutdown()
â”‚       â”œâ”€â”€ app.on('before-quit') â†’ this.shutdown()
â”‚       â””â”€â”€ app.on('activate') â†’ this.createMainWindow()
â””â”€â”€ app.whenReady() â†’ appController.createMainWindow()
```

### 2. Async Service Initialization

```
ApplicationController.initialize() [âš¡async]
â”œâ”€â”€ initializeServicesAsync()
â”‚   â”œâ”€â”€ configurationManager.initialize() [âš¡]
â”‚   â”‚   â”œâ”€â”€ loadConfig() â†’ JSON.parse(configFile)
â”‚   â”‚   â””â”€â”€ validateConfiguration()
â”‚   â”œâ”€â”€ promptLibraryService.addPersona('quantitative-finance-engineer') [âš¡]
â”‚   â”‚   â”œâ”€â”€ checkPersonaExists() â†’ boolean
â”‚   â”‚   â”œâ”€â”€ â“ if (!exists) â†’ addToPersonaList()
â”‚   â”‚   â””â”€â”€ âš ï¸ else â†’ throw Error("already exists")
â”‚   â”œâ”€â”€ audioService.initialize() [âš¡]
â”‚   â”‚   â”œâ”€â”€ checkFFmpegAvailability() â†’ execAsync('ffmpeg -version')
â”‚   â”‚   â”œâ”€â”€ checkWhisperAvailability() â†’ fs.access(whisperPath)
â”‚   â”‚   â”œâ”€â”€ detectAudioDevices() â†’ execAsync('ffmpeg -f avfoundation -list_devices')
â”‚   â”‚   â”œâ”€â”€ parseDeviceList() â†’ {microphones: [], systems: []}
â”‚   â”‚   â””â”€â”€ this.isInitialized = true
â”‚   â”œâ”€â”€ ocrService.initialize() [âš¡]
â”‚   â”‚   â”œâ”€â”€ createWorker() â†’ tesseract.createWorker()
â”‚   â”‚   â”œâ”€â”€ worker.loadLanguage('eng') [âš¡]
â”‚   â”‚   â”œâ”€â”€ worker.initialize('eng') [âš¡]
â”‚   â”‚   â””â”€â”€ this.worker = worker
â”‚   â””â”€â”€ globalRagService.initialize() [âš¡]
â”‚       â”œâ”€â”€ createDatabaseConnection() â†’ new LanceDB()
â”‚       â”œâ”€â”€ ensureVectorTable() â†’ table = db.createTable()
â”‚       â””â”€â”€ this.isReady = true
â”œâ”€â”€ initializeOpenAI()
â”‚   â”œâ”€â”€ â“ configurationManager.isApiKeyConfigured()
â”‚   â”œâ”€â”€ YES â†’ apiKey = configurationManager.getApiKey()
â”‚   â”œâ”€â”€ NO â†’ apiKey = store.get('openai-api-key')
â”‚   â”œâ”€â”€ â“ if (apiKey)
â”‚   â”‚   â”œâ”€â”€ this.openai = new OpenAI({apiKey})
â”‚   â”‚   â””â”€â”€ âœ… OpenAI client ready
â”‚   â””â”€â”€ âŒ else â†’ this.openai = null
â”œâ”€â”€ setupIPC()
â”‚   â”œâ”€â”€ new IPCController(this.getServices(), windows, sessions, callback)
â”‚   â””â”€â”€ ipcController.initialize()
â”‚       â”œâ”€â”€ setupSessionHandlers()
â”‚       â”œâ”€â”€ setupChatHandlers()
â”‚       â”œâ”€â”€ setupScreenshotHandlers()
â”‚       â”œâ”€â”€ setupAudioHandlers()
â”‚       â”œâ”€â”€ setupRAGHandlers()
â”‚       â”œâ”€â”€ setupGlobalRAGHandlers()
â”‚       â”œâ”€â”€ setupSettingsHandlers()
â”‚       â””â”€â”€ setupAPIKeyHandlers()
â”œâ”€â”€ â“ if (config.stealthMode) â†’ setupStealthMode()
â”‚   â”œâ”€â”€ process.title = 'systemAssistance'
â”‚   â”œâ”€â”€ â“ if (darwin) â†’ app.dock?.hide()
â”‚   â””â”€â”€ startScreenSharingDetection()
â”‚       â”œâ”€â”€ new ScreenSharingDetectionService(config, callback)
â”‚       â””â”€â”€ detectionService.start()
â””â”€â”€ setupGlobalHotkeys()
    â”œâ”€â”€ globalShortcut.register('CommandOrControl+G', toggleMainWindow)
    â””â”€â”€ globalShortcut.register('CommandOrControl+H', hideAllSessionWindows)
```

---

## Session Management Flows

### 1. Session Creation Flow

```
Main Window: User clicks "Start Session"
â”œâ”€â”€ ğŸ¯ ipcRenderer.send('create-session', {profession, interviewType, context})
â””â”€â”€ IPCController.setupSessionHandlers() receives event

IPCController.on('create-session')
â”œâ”€â”€ sessionManager.createSession(config) [âš¡]
â”‚   â”œâ”€â”€ generateSessionId() â†’ uuid.v4()
â”‚   â”œâ”€â”€ validateSessionConfig(config) â†’ boolean
â”‚   â”œâ”€â”€ session = {
â”‚   â”‚   id: sessionId,
â”‚   â”‚   profession: config.profession,
â”‚   â”‚   interviewType: config.interviewType,
â”‚   â”‚   context: config.context,
â”‚   â”‚   createdAt: new Date(),
â”‚   â”‚   isActive: true,
â”‚   â”‚   chatHistory: [],
â”‚   â”‚   isRecording: false,
â”‚   â”‚   hasRAG: false
â”‚   â”‚   }
â”‚   â”œâ”€â”€ ğŸ’¾ persistSession(session)
â”‚   â””â”€â”€ return session
â”œâ”€â”€ createSessionWindowCallback(sessionId, config)
â”‚   â”œâ”€â”€ ApplicationController.createSessionWindow(sessionId, config)
â”‚   â”‚   â”œâ”€â”€ new BrowserWindow(stealthConfig)
â”‚   â”‚   â”œâ”€â”€ loadSessionWindowContent(window, sessionId, config)
â”‚   â”‚   â”‚   â”œâ”€â”€ sessionHtmlPath = path.join(__dirname, 'session.html')
â”‚   â”‚   â”‚   â”œâ”€â”€ window.loadFile(sessionHtmlPath)
â”‚   â”‚   â”‚   â””â”€â”€ window.webContents.once('dom-ready') â†’
â”‚   â”‚   â”‚       window.executeJavaScript(`window.GHOST_GUIDE_SESSION_ID = '${sessionId}'`)
â”‚   â”‚   â”œâ”€â”€ setupSessionWindowEvents(window, sessionId)
â”‚   â”‚   â”‚   â””â”€â”€ window.on('closed') â†’ cleanup session data
â”‚   â”‚   â”œâ”€â”€ â“ if (stealthMode) â†’ window.setContentProtection(true)
â”‚   â”‚   â”œâ”€â”€ sessionWindows.set(sessionId, window)
â”‚   â”‚   â”œâ”€â”€ sessions.set(sessionId, sessionData)
â”‚   â”‚   â””â”€â”€ return window
â”‚   â””â”€â”€ initializeChatSessionWithContext(sessionId, profession, type, context) [âš¡]
â”‚       â”œâ”€â”€ â“ if (!openai) â†’ skip initialization
â”‚       â”œâ”€â”€ searchGlobalRAG(profession, interviewType, context) [âš¡]
â”‚       â”‚   â”œâ”€â”€ buildSearchQueries() â†’ string[]
â”‚       â”‚   â”‚   â”œâ”€â”€ `${profession} ${interviewType} experience`
â”‚       â”‚   â”‚   â”œâ”€â”€ `${profession} background skills`
â”‚       â”‚   â”‚   â”œâ”€â”€ userContext (if provided)
â”‚       â”‚   â”‚   â””â”€â”€ general resume queries
â”‚       â”‚   â”œâ”€â”€ ğŸ”„ for each query:
â”‚       â”‚   â”‚   â”œâ”€â”€ globalRagService.searchRelevantContext(query, 3) [âš¡]
â”‚       â”‚   â”‚   â””â”€â”€ allSearchResults.push(...results)
â”‚       â”‚   â”œâ”€â”€ removeResultDuplicates() â†’ uniqueResults
â”‚       â”‚   â”œâ”€â”€ sortByRelevanceScore() â†’ topResults
â”‚       â”‚   â””â”€â”€ formatGlobalContext() â†’ contextString
â”‚       â”œâ”€â”€ buildComprehensiveContextMessage()
â”‚       â”‚   â”œâ”€â”€ `ğŸ¯ **INTERVIEW SESSION STARTED**`
â”‚       â”‚   â”œâ”€â”€ `**Role:** ${profession}`
â”‚       â”‚   â”œâ”€â”€ `**Interview Type:** ${interviewType}`
â”‚       â”‚   â”œâ”€â”€ â“ if (userContext) â†’ include context section
â”‚       â”‚   â”œâ”€â”€ â“ if (globalContext) â†’ include background section
â”‚       â”‚   â””â”€â”€ instructions for AI assistant
â”‚       â”œâ”€â”€ chatService.sendMessage(sessionId, contextMessage, true) [âš¡]
â”‚       â”‚   â””â”€â”€ [See Chat Interaction Flow]
â”‚       â””â”€â”€ sendToSessionWindow(contextMessage, aiResponse)
â”‚           â”œâ”€â”€ sessionWindow.webContents.send('chat-response', contextData)
â”‚           â””â”€â”€ sessionWindow.webContents.send('chat-response', aiResponseData)
â””â”€â”€ ğŸ¯ event.reply('session-created', {sessionId, session})
```

### 2. Session Cleanup Flow

```
User closes session window OR clicks "Close Session"
â”œâ”€â”€ ğŸ¯ ipcRenderer.send('close-session', sessionId)
â””â”€â”€ IPCController.on('close-session')

IPCController.on('close-session')
â”œâ”€â”€ â“ if (audioService.getRecordingStatus(sessionId).isRecording)
â”‚   â””â”€â”€ audioService.stopRecording(sessionId) [âš¡]
â”œâ”€â”€ sessionManager.closeSession(sessionId) [âš¡]
â”‚   â”œâ”€â”€ session = getSession(sessionId)
â”‚   â”œâ”€â”€ â“ if (!session) â†’ throw Error('Session not found')
â”‚   â”œâ”€â”€ session.isActive = false
â”‚   â”œâ”€â”€ ğŸ’¾ persistSessionState(session)
â”‚   â”œâ”€â”€ cleanupSessionResources(sessionId)
â”‚   â”‚   â”œâ”€â”€ clearAccumulatedOCR(sessionId)
â”‚   â”‚   â”œâ”€â”€ stopAnyActiveRecordings(sessionId)
â”‚   â”‚   â””â”€â”€ cleanupRAGData(sessionId)
â”‚   â””â”€â”€ sessions.delete(sessionId)
â”œâ”€â”€ sessionWindows.delete(sessionId)
â””â”€â”€ ğŸ¯ event.reply('session-closed', {sessionId})
```

---

## Screenshot Analysis Flow

### 1. Single Screenshot Capture

```
Session Window: User clicks "Screenshot"
â”œâ”€â”€ ğŸ¯ ipcRenderer.send('capture-screenshot', {sessionId})
â””â”€â”€ IPCController.setupScreenshotHandlers() receives event

IPCController.on('capture-screenshot')
â”œâ”€â”€ session = sessions.get(sessionId)
â”œâ”€â”€ captureService.captureScreen() [âš¡]
â”‚   â”œâ”€â”€ getScreenDimensions() â†’ {width, height}
â”‚   â”œâ”€â”€ â“ platform-specific capture
â”‚   â”‚   â”œâ”€â”€ macOS: execAsync('screencapture -t png -')
â”‚   â”‚   â”œâ”€â”€ Windows: nativeCapture.takeScreenshot()
â”‚   â”‚   â””â”€â”€ Linux: execAsync('import -window root png:-')
â”‚   â”œâ”€â”€ ğŸ“ imageBuffer = processScreenshotData()
â”‚   â””â”€â”€ return Buffer
â”œâ”€â”€ ocrService.extractText(screenshot) [âš¡]
â”‚   â”œâ”€â”€ preprocessImage(imageBuffer)
â”‚   â”‚   â”œâ”€â”€ convertToGrayscale()
â”‚   â”‚   â”œâ”€â”€ adjustContrast()
â”‚   â”‚   â””â”€â”€ resizeForOCR()
â”‚   â”œâ”€â”€ worker.recognize(imageBuffer) [âš¡]
â”‚   â”œâ”€â”€ ğŸ“ extractTextFromResult() â†’ rawText
â”‚   â”œâ”€â”€ postprocessText(rawText)
â”‚   â”‚   â”œâ”€â”€ removeExtraWhitespace()
â”‚   â”‚   â”œâ”€â”€ fixCommonOCRErrors()
â”‚   â”‚   â””â”€â”€ cleanSpecialCharacters()
â”‚   â””â”€â”€ return cleanText
â”œâ”€â”€ initializeSessionOCRAccumulation()
â”‚   â”œâ”€â”€ â“ if (!session.accumulatedOCR) â†’ session.accumulatedOCR = {}
â”‚   â””â”€â”€ session.accumulatedOCR['screenshot'] = ocrText
â”œâ”€â”€ findSessionWindow(sessionId)
â”‚   â”œâ”€â”€ sessionWindow = sessionWindows.get(sessionId)
â”‚   â””â”€â”€ â“ validate window exists and not destroyed
â””â”€â”€ ğŸ¯ sessionWindow.webContents.send('screenshot-captured', {
    sessionId, text: ocrText, accumulatedText: ocrText, timestamp
    })
```

### 2. Multi-Step Screenshot Capture

```
Session Window: User selects "Capture Left Half" / "Capture Right Half"
â”œâ”€â”€ ğŸ¯ ipcRenderer.send('multi-capture', {sessionId, actionType, captureType, accumulatedText})
â””â”€â”€ IPCController.on('multi-capture')

IPCController.on('multi-capture')
â”œâ”€â”€ session = sessions.get(sessionId)
â”œâ”€â”€ mapCaptureTypeToEnum(captureType) â†’ CaptureType
â”‚   â”œâ”€â”€ 'full' â†’ CaptureType.FULL
â”‚   â”œâ”€â”€ 'left_half' â†’ CaptureType.LEFT_HALF
â”‚   â””â”€â”€ 'right_half' â†’ CaptureType.RIGHT_HALF
â”œâ”€â”€ captureService.captureScreenWithType(captureTypeEnum) [âš¡]
â”‚   â”œâ”€â”€ captureFullScreen() â†’ fullScreenshot
â”‚   â”œâ”€â”€ getScreenDimensions() â†’ {width, height}
â”‚   â”œâ”€â”€ â“ switch (captureType)
â”‚   â”‚   â”œâ”€â”€ FULL â†’ return fullScreenshot
â”‚   â”‚   â”œâ”€â”€ LEFT_HALF â†’ cropImageLeft(fullScreenshot, width/2)
â”‚   â”‚   â””â”€â”€ RIGHT_HALF â†’ cropImageRight(fullScreenshot, width/2)
â”‚   â”œâ”€â”€ ğŸ“ processedImage = applyCropping()
â”‚   â””â”€â”€ return Buffer
â”œâ”€â”€ ocrService.extractText(newScreenshot) [âš¡]
â”‚   â””â”€â”€ [Same OCR process as above]
â”œâ”€â”€ accumulateOCRText()
â”‚   â”œâ”€â”€ combinedText = accumulatedText ? 
â”‚   â”‚   `${accumulatedText}\n\n--- Additional Capture ---\n\n${newOcrText}` 
â”‚   â”‚   : newOcrText
â”‚   â””â”€â”€ session.accumulatedOCR[actionType] = combinedText
â””â”€â”€ ğŸ¯ event.reply('screenshot-captured', {
    sessionId, text: newOcrText, accumulatedText: combinedText, 
    captureType, timestamp
    })
```

### 3. Screenshot Analysis with AI

```
Session Window: User clicks "Analyze Complete Text"
â”œâ”€â”€ ğŸ¯ ipcRenderer.send('analyze-accumulated-text', {sessionId, actionType, accumulatedText})
â””â”€â”€ IPCController.on('analyze-accumulated-text')

IPCController.on('analyze-accumulated-text')
â”œâ”€â”€ session = sessions.get(sessionId)
â”œâ”€â”€ â“ if (chatService.isConfigured() && session)
â”‚   â”œâ”€â”€ determineActionType() â†’ action = actionType === 'screenshot' ? ActionType.SCREENSHOT : ActionType.DEBUG
â”‚   â”œâ”€â”€ chatService.processOCRText(sessionId, accumulatedText, action) [âš¡]
â”‚   â”‚   â”œâ”€â”€ session = sessionManager.getSession(sessionId)
â”‚   â”‚   â”œâ”€â”€ â“ if (!session) â†’ throw Error('Session not found')
â”‚   â”‚   â”œâ”€â”€ promptLibraryService.getActionPrompt(action, profession, interviewType)
â”‚   â”‚   â”‚   â”œâ”€â”€ buildActionPromptTemplate(action)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ACTION.SCREENSHOT â†’ screenshotAnalysisTemplate
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ACTION.DEBUG â†’ debugAnalysisTemplate
â”‚   â”‚   â”‚   â”œâ”€â”€ customizeForProfession(template, profession)
â”‚   â”‚   â”‚   â”œâ”€â”€ customizeForInterviewType(template, interviewType)
â”‚   â”‚   â”‚   â””â”€â”€ return formattedPrompt
â”‚   â”‚   â”œâ”€â”€ formatMessageWithOCRText(prompt, accumulatedText)
â”‚   â”‚   â”œâ”€â”€ addToConversationHistory(sessionId, userMessage)
â”‚   â”‚   â”œâ”€â”€ openai.chat.completions.create({
â”‚   â”‚   â”‚   model: 'gpt-4',
â”‚   â”‚   â”‚   messages: conversationHistory,
â”‚   â”‚   â”‚   max_tokens: 1500,
â”‚   â”‚   â”‚   temperature: 0.3
â”‚   â”‚   â”‚   }) [âš¡]
â”‚   â”‚   â”œâ”€â”€ ğŸ“ aiResponse = completion.choices[0].message.content
â”‚   â”‚   â”œâ”€â”€ addToConversationHistory(sessionId, aiMessage)
â”‚   â”‚   â”œâ”€â”€ updateTokenUsage(completion.usage)
â”‚   â”‚   â””â”€â”€ return aiResponse
â”‚   â””â”€â”€ âœ… analysisResult = aiResponse
â”œâ”€â”€ âŒ else â†’ fallbackAnalysis
â”‚   â”œâ”€â”€ generateFallbackAnalysis(accumulatedText, profession, interviewType)
â”‚   â”‚   â”œâ”€â”€ promptLibraryService.getFallbackAnalysisPrompt(ocrText, profession, type)
â”‚   â”‚   â”œâ”€â”€ buildFallbackTemplate()
â”‚   â”‚   â”‚   â”œâ”€â”€ analysis header with detected text
â”‚   â”‚   â”‚   â”œâ”€â”€ profession-specific approach guidelines
â”‚   â”‚   â”‚   â”œâ”€â”€ general strategy recommendations
â”‚   â”‚   â”‚   â”œâ”€â”€ interview tips
â”‚   â”‚   â”‚   â””â”€â”€ API key configuration prompt
â”‚   â”‚   â””â”€â”€ return formattedFallbackText
â”‚   â””â”€â”€ analysisResult = fallbackText
â”œâ”€â”€ ğŸ¯ event.reply('chat-response', {
â”‚   sessionId, 
â”‚   content: `ğŸ“ **Complete Analysis:**\n\n${analysisResult}`,
â”‚   metadata: {action: actionType, analysisType: 'accumulated'},
â”‚   timestamp
â”‚   })
â””â”€â”€ cleanupAccumulatedText()
    â””â”€â”€ delete session.accumulatedOCR[actionType]
```

---

## Audio Recording Flow

### 1. Start Recording

```
Session Window: User clicks "Record Mic" / "Record System"
â”œâ”€â”€ ğŸ¯ ipcRenderer.send('start-recording', {sessionId, source})
â””â”€â”€ IPCController.on('start-recording')

IPCController.on('start-recording')
â”œâ”€â”€ session = sessions.get(sessionId)
â”œâ”€â”€ â“ if (!session) â†’ reply with error
â”œâ”€â”€ â“ if (!audioService.isReady()) 
â”‚   â””â”€â”€ audioService.initialize() [âš¡]
â”œâ”€â”€ mapSourceToAudioSource(source) â†’ AudioSource
â”‚   â”œâ”€â”€ 'interviewer' â†’ AudioSource.INTERVIEWER  
â”‚   â”œâ”€â”€ 'interviewee' â†’ AudioSource.INTERVIEWEE
â”‚   â”œâ”€â”€ 'both' â†’ AudioSource.BOTH
â”‚   â””â”€â”€ 'system' â†’ AudioSource.SYSTEM
â”œâ”€â”€ audioService.startRecording(audioSource, sessionId) [âš¡]
â”‚   â”œâ”€â”€ validateRecordingParams(source, sessionId)
â”‚   â”œâ”€â”€ â“ if (isAlreadyRecording(sessionId)) â†’ stopExistingRecording()
â”‚   â”œâ”€â”€ determineAudioDevice(audioSource)
â”‚   â”‚   â”œâ”€â”€ AudioSource.INTERVIEWEE â†’ microphoneDeviceId
â”‚   â”‚   â”œâ”€â”€ AudioSource.SYSTEM â†’ systemAudioDeviceId  
â”‚   â”‚   â””â”€â”€ AudioSource.BOTH â†’ combinedDeviceSetup
â”‚   â”œâ”€â”€ generateOutputFilePath(sessionId) â†’ tempAudioFile
â”‚   â”œâ”€â”€ buildFFmpegCommand(deviceId, outputFile)
â”‚   â”‚   â””â”€â”€ `ffmpeg -y -f avfoundation -i :${deviceId} -ac 1 -ar 16000 -acodec pcm_s16le ${outputFile}`
â”‚   â”œâ”€â”€ spawn(ffmpegCommand) â†’ recordingProcess
â”‚   â”œâ”€â”€ setupProcessEventHandlers()
â”‚   â”‚   â”œâ”€â”€ process.stderr.on('data') â†’ logRecordingProgress()
â”‚   â”‚   â”œâ”€â”€ process.on('close') â†’ handleRecordingComplete()
â”‚   â”‚   â””â”€â”€ process.on('error') â†’ handleRecordingError()
â”‚   â”œâ”€â”€ recordingSessions.set(sessionId, {process, outputFile, source})
â”‚   â””â”€â”€ âœ… recording started
â”œâ”€â”€ updateSessionState()
â”‚   â”œâ”€â”€ session.isRecording = true
â”‚   â””â”€â”€ session.recordingSource = audioSource
â””â”€â”€ ğŸ¯ event.reply('recording-status', {sessionId, isRecording: true, source})
```

### 2. Stop Recording and Transcription

```
Session Window: User clicks "Stop Recording"
â”œâ”€â”€ ğŸ¯ ipcRenderer.send('stop-recording', {sessionId})
â””â”€â”€ IPCController.on('stop-recording')

IPCController.on('stop-recording')
â”œâ”€â”€ session = sessions.get(sessionId)
â”œâ”€â”€ audioService.stopRecording(sessionId) [âš¡]
â”‚   â”œâ”€â”€ recordingData = recordingSessions.get(sessionId)
â”‚   â”œâ”€â”€ â“ if (!recordingData) â†’ return null
â”‚   â”œâ”€â”€ terminateFFmpegProcess()
â”‚   â”‚   â”œâ”€â”€ process.kill('SIGTERM')
â”‚   â”‚   â””â”€â”€ await processClose
â”‚   â”œâ”€â”€ calculateRecordingDuration() â†’ totalDuration
â”‚   â”œâ”€â”€ extractFinalAudioSegment() [âš¡]
â”‚   â”‚   â”œâ”€â”€ â“ if (totalDuration <= 10s) â†’ use full recording
â”‚   â”‚   â”œâ”€â”€ âŒ else â†’ extract last 10 seconds
â”‚   â”‚   â”œâ”€â”€ buildFinalSegmentCommand()
â”‚   â”‚   â”‚   â””â”€â”€ `ffmpeg -i ${inputFile} -ss ${startTime} -t ${duration} -c copy ${finalFile}`
â”‚   â”‚   â”œâ”€â”€ execAsync(segmentCommand)
â”‚   â”‚   â””â”€â”€ return finalAudioFile
â”‚   â”œâ”€â”€ transcribeWithWhisper(finalAudioFile) [âš¡]
â”‚   â”‚   â”œâ”€â”€ buildWhisperCommand()
â”‚   â”‚   â”‚   â””â”€â”€ `whisper-cli --model ggml-base.en.bin --output-txt --no-prints ${audioFile}`
â”‚   â”‚   â”œâ”€â”€ execAsync(whisperCommand) [âš¡]
â”‚   â”‚   â”œâ”€â”€ ğŸ“ parseTranscriptionOutput() â†’ transcriptionText
â”‚   â”‚   â”œâ”€â”€ cleanTranscriptionText()
â”‚   â”‚   â”‚   â”œâ”€â”€ removeTimestamps()
â”‚   â”‚   â”‚   â”œâ”€â”€ fixCommonTranscriptionErrors()
â”‚   â”‚   â”‚   â””â”€â”€ normalizeWhitespace()
â”‚   â”‚   â””â”€â”€ return cleanedTranscription
â”‚   â”œâ”€â”€ accumulateTranscription(sessionId, transcription)
â”‚   â”‚   â”œâ”€â”€ existingTranscript = accumulatedTranscriptions.get(sessionId) || ''
â”‚   â”‚   â”œâ”€â”€ completeTranscript = existingTranscript + transcription
â”‚   â”‚   â””â”€â”€ accumulatedTranscriptions.set(sessionId, completeTranscript)
â”‚   â”œâ”€â”€ cleanupAudioFiles()
â”‚   â”‚   â”œâ”€â”€ â“ if (!DEBUG_AUDIO) â†’ fs.unlink(tempFiles)
â”‚   â”‚   â””â”€â”€ âœ… else â†’ preserve for debugging
â”‚   â””â”€â”€ return completeTranscription
â”œâ”€â”€ updateSessionState()
â”‚   â”œâ”€â”€ session.isRecording = false
â”‚   â”œâ”€â”€ recordingSource = session.recordingSource
â”‚   â””â”€â”€ session.recordingSource = null
â”œâ”€â”€ ğŸ¯ sessionWindow.send('chat-response', {
â”‚   sessionId, content: `ğŸ¤ **Complete Transcription:** ${transcription}`,
â”‚   timestamp, source: 'complete-audio-transcription'
â”‚   })
â”œâ”€â”€ â“ if (chatService.isConfigured() && session)
â”‚   â”œâ”€â”€ chatService.processTranscript(sessionId, transcription, recordingSource) [âš¡]
â”‚   â”‚   â”œâ”€â”€ session = sessionManager.getSession(sessionId)
â”‚   â”‚   â”œâ”€â”€ promptLibraryService.getAudioCoachingPrompt(audioSource, profession, interviewType)
â”‚   â”‚   â”‚   â”œâ”€â”€ determineCoachingContext(audioSource)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ INTERVIEWER â†’ "analyzing interviewer questions"
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ INTERVIEWEE â†’ "coaching user responses"  
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ SYSTEM â†’ "analyzing system audio"
â”‚   â”‚   â”‚   â”œâ”€â”€ buildCoachingPromptTemplate()
â”‚   â”‚   â”‚   â”œâ”€â”€ customizeForProfession(template, profession)
â”‚   â”‚   â”‚   â””â”€â”€ customizeForInterviewType(template, interviewType)
â”‚   â”‚   â”œâ”€â”€ formatTranscriptMessage(prompt, transcription)
â”‚   â”‚   â”œâ”€â”€ addToConversationHistory(sessionId, transcriptMessage)
â”‚   â”‚   â”œâ”€â”€ openai.chat.completions.create() [âš¡]
â”‚   â”‚   â”œâ”€â”€ ğŸ“ coachingResponse = completion.choices[0].message.content
â”‚   â”‚   â”œâ”€â”€ addToConversationHistory(sessionId, coachingMessage)  
â”‚   â”‚   â””â”€â”€ return coachingResponse
â”‚   â””â”€â”€ ğŸ¯ sessionWindow.send('chat-response', {
â”‚       sessionId, content: `ğŸ¤– **AI Analysis:** ${coachingResponse}`,
â”‚       timestamp, source: 'complete-audio-analysis'
â”‚       })
â””â”€â”€ ğŸ¯ event.reply('recording-status', {sessionId, isRecording: false})
```

---

## RAG Knowledge Base Flow

### 1. Session-Specific RAG

```
Session Window: User clicks "RAG"
â”œâ”€â”€ ğŸ¯ ipcRenderer.send('add-rag-material', {sessionId})
â””â”€â”€ IPCController.on('add-rag-material')

IPCController.on('add-rag-material')
â”œâ”€â”€ showFolderSelectionDialog() [âš¡]
â”‚   â”œâ”€â”€ dialog.showOpenDialog({
â”‚   â”‚   title: 'Select Study Materials Folder',
â”‚   â”‚   properties: ['openDirectory']
â”‚   â”‚   })
â”‚   â””â”€â”€ â“ if (canceled) â†’ return early
â”œâ”€â”€ ragService.ingestDocuments(folderPath, sessionId) [âš¡]
â”‚   â”œâ”€â”€ scanDirectoryForDocuments(folderPath)
â”‚   â”‚   â”œâ”€â”€ fs.readdir(folderPath, {recursive: true})
â”‚   â”‚   â”œâ”€â”€ filterSupportedFiles() â†’ ['.txt', '.md', '.pdf']
â”‚   â”‚   â””â”€â”€ return documentPaths[]
â”‚   â”œâ”€â”€ ğŸ”„ for each documentPath:
â”‚   â”‚   â”œâ”€â”€ readFileContent(documentPath) â†’ rawContent
â”‚   â”‚   â”œâ”€â”€ extractTextFromFile(rawContent, fileType)
â”‚   â”‚   â”‚   â”œâ”€â”€ '.txt' â†’ readAsUTF8()
â”‚   â”‚   â”‚   â”œâ”€â”€ '.md' â†’ parseMarkdown()
â”‚   â”‚   â”‚   â””â”€â”€ '.pdf' â†’ extractWithPDFParser()
â”‚   â”‚   â”œâ”€â”€ chunkDocument(extractedText)
â”‚   â”‚   â”‚   â”œâ”€â”€ splitIntoSentences()
â”‚   â”‚   â”‚   â”œâ”€â”€ combineIntoChunks(maxChunkSize: 1000)
â”‚   â”‚   â”‚   â””â”€â”€ return textChunks[]
â”‚   â”‚   â”œâ”€â”€ generateEmbeddings(textChunks) [âš¡]
â”‚   â”‚   â”‚   â”œâ”€â”€ â“ if (openaiConfigured)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ openai.embeddings.create({input: chunks})
â”‚   â”‚   â”‚   â””â”€â”€ âŒ else â†’ generateLocalEmbeddings()
â”‚   â”‚   â”œâ”€â”€ storeInKnowledgeBase()
â”‚   â”‚   â”‚   â”œâ”€â”€ documentId = generateId()
â”‚   â”‚   â”‚   â”œâ”€â”€ documentMetadata = {filename, path, size, type}
â”‚   â”‚   â”‚   â”œâ”€â”€ knowledgeBase.documents.push({id, content, metadata})
â”‚   â”‚   â”‚   â””â”€â”€ knowledgeBase.embeddings.push(embeddings)
â”‚   â”‚   â””â”€â”€ processedDocuments++
â”‚   â”œâ”€â”€ ğŸ’¾ persistKnowledgeBase(sessionId, knowledgeBase)
â”‚   â””â”€â”€ return {documentsProcessed, knowledgeBase}
â”œâ”€â”€ updateSessionRAGStatus()
â”‚   â””â”€â”€ session.hasRAG = true
â””â”€â”€ ğŸ¯ event.reply('rag-success', {
    sessionId, documentsProcessed, folderPath, timestamp
    })
```

### 2. Global RAG Search

```
Session Initialization: searchRelevantContext()
â”œâ”€â”€ buildSearchQueries(profession, interviewType, context)
â”‚   â”œâ”€â”€ baseQueries = [`${profession} ${interviewType} experience`, `${profession} background skills`]
â”‚   â”œâ”€â”€ â“ if (context) â†’ extractContextKeywords() â†’ additionalQueries
â”‚   â””â”€â”€ return allQueries
â”œâ”€â”€ ğŸ”„ for each searchQuery:
â”‚   â”œâ”€â”€ globalRagService.searchRelevantContext(query, limit) [âš¡]
â”‚   â”‚   â”œâ”€â”€ â“ if (!isReady()) â†’ return []
â”‚   â”‚   â”œâ”€â”€ generateQueryEmbedding(query) [âš¡]
â”‚   â”‚   â”‚   â””â”€â”€ openai.embeddings.create({input: query})
â”‚   â”‚   â”œâ”€â”€ performVectorSearch(queryEmbedding)
â”‚   â”‚   â”‚   â”œâ”€â”€ lanceDB.search(queryEmbedding)
â”‚   â”‚   â”‚   â”œâ”€â”€ calculateSimilarityScores()
â”‚   â”‚   â”‚   â””â”€â”€ rankResultsByRelevance()
â”‚   â”‚   â”œâ”€â”€ retrieveTopMatches(limit)
â”‚   â”‚   â”‚   â””â”€â”€ return SearchResult[]{id, text, score, metadata}
â”‚   â”‚   â””â”€â”€ return rankedResults
â”‚   â””â”€â”€ allResults.push(...searchResults)
â”œâ”€â”€ removeDuplicateResults()
â”‚   â””â”€â”€ uniqueResults = results.filter(unique by id)
â”œâ”€â”€ sortAndLimitResults()
â”‚   â”œâ”€â”€ sortedResults = results.sort(by score descending)  
â”‚   â””â”€â”€ topResults = sortedResults.slice(0, maxResults)
â”œâ”€â”€ ğŸ“ formatContextFromResults()
â”‚   â”œâ”€â”€ contextText = results.map(r => r.text).join('\n\n')
â”‚   â”œâ”€â”€ cleanupContextText()
â”‚   â”‚   â”œâ”€â”€ normalizeWhitespace()
â”‚   â”‚   â”œâ”€â”€ ensureProperPunctuation()
â”‚   â”‚   â””â”€â”€ removeDuplicateContent()
â”‚   â””â”€â”€ return formattedContext
â””â”€â”€ return {contextText, totalResults: results.length}
```

---

## Chat Interaction Flow

### 1. Regular Chat Message

```
Session Window: User types message and presses Enter
â”œâ”€â”€ ğŸ¯ ipcRenderer.send('chat-message', {sessionId, message, source})
â””â”€â”€ IPCController.on('chat-message')

IPCController.on('chat-message')
â”œâ”€â”€ session = sessions.get(sessionId)
â”œâ”€â”€ â“ if (openai && session)
â”‚   â”œâ”€â”€ determineMessageContext(source)
â”‚   â”‚   â”œâ”€â”€ source === 'audio-transcription' â†’ contextualMessage = `[Audio] ${message}`
â”‚   â”‚   â””â”€â”€ âŒ else â†’ contextualMessage = message
â”‚   â”œâ”€â”€ chatService.sendMessage(sessionId, contextualMessage) [âš¡]
â”‚   â”‚   â”œâ”€â”€ session = sessionManager.getSession(sessionId)
â”‚   â”‚   â”œâ”€â”€ â“ if (!session) â†’ throw Error('Session not found')
â”‚   â”‚   â”œâ”€â”€ â“ if (isInitialization) â†’ buildSystemPrompt()
â”‚   â”‚   â”‚   â”œâ”€â”€ promptLibraryService.getSystemPrompt(profession, interviewType)
â”‚   â”‚   â”‚   â””â”€â”€ initializeConversationHistory(sessionId, systemMessage)
â”‚   â”‚   â”œâ”€â”€ âŒ else â†’ buildUserMessage()
â”‚   â”‚   â”‚   â”œâ”€â”€ promptLibraryService.getActionPrompt(ActionType.CHAT, profession, interviewType)
â”‚   â”‚   â”‚   â””â”€â”€ formatUserMessage(actionPrompt, message)
â”‚   â”‚   â”œâ”€â”€ retrieveConversationHistory(sessionId) â†’ messages[]
â”‚   â”‚   â”œâ”€â”€ addNewMessageToHistory(sessionId, userMessage)
â”‚   â”‚   â”œâ”€â”€ callOpenAIAPI() [âš¡]
â”‚   â”‚   â”‚   â”œâ”€â”€ openai.chat.completions.create({
â”‚   â”‚   â”‚   â”‚   model: 'gpt-4',
â”‚   â”‚   â”‚   â”‚   messages: conversationHistory,
â”‚   â”‚   â”‚   â”‚   max_tokens: 1000,
â”‚   â”‚   â”‚   â”‚   temperature: 0.3
â”‚   â”‚   â”‚   â”‚   })
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ aiResponse = completion.choices[0].message.content
â”‚   â”‚   â”‚   â””â”€â”€ logTokenUsage(completion.usage)
â”‚   â”‚   â”œâ”€â”€ addAIResponseToHistory(sessionId, aiResponse)
â”‚   â”‚   â”œâ”€â”€ ğŸ’¾ persistConversationHistory(sessionId)
â”‚   â”‚   â””â”€â”€ return aiResponse
â”‚   â””â”€â”€ âœ… response = aiResponse
â”œâ”€â”€ âŒ else â†’ generateFallbackResponse()
â”‚   â”œâ”€â”€ fallbackResponses = [
â”‚   â”‚   'Great question! For technical interviews...',
â”‚   â”‚   'This is a common interview pattern...',
â”‚   â”‚   'I can see this relates to algorithms...'
â”‚   â”‚   ]
â”‚   â””â”€â”€ response = randomChoice(fallbackResponses)
â””â”€â”€ ğŸ¯ event.reply('chat-response', {sessionId, content: response, timestamp})
```

### 2. Conversation History Management

```
ChatService.conversationHistory
â”œâ”€â”€ sessionHistories: Map<sessionId, messages[]>
â”œâ”€â”€ addToConversationHistory(sessionId, message)
â”‚   â”œâ”€â”€ history = sessionHistories.get(sessionId) || []
â”‚   â”œâ”€â”€ history.push({role, content, timestamp})
â”‚   â”œâ”€â”€ â“ if (history.length > maxHistoryLength)
â”‚   â”‚   â””â”€â”€ history = history.slice(-maxHistoryLength)
â”‚   â”œâ”€â”€ sessionHistories.set(sessionId, history)
â”‚   â””â”€â”€ ğŸ’¾ persistConversationState(sessionId)
â”œâ”€â”€ getConversationHistory(sessionId) â†’ messages[]
â”œâ”€â”€ clearConversationHistory(sessionId)
â”‚   â”œâ”€â”€ sessionHistories.delete(sessionId)
â”‚   â””â”€â”€ ğŸ’¾ removePersistedState(sessionId)
â””â”€â”€ initializeConversation(sessionId, systemPrompt)
    â”œâ”€â”€ systemMessage = {role: 'system', content: systemPrompt}
    â””â”€â”€ sessionHistories.set(sessionId, [systemMessage])
```

---

## Configuration Flow

### 1. API Key Configuration

```
Settings Window: User enters API key
â”œâ”€â”€ ğŸ¯ ipcRenderer.send('save-api-key', apiKey)
â””â”€â”€ IPCController.on('save-api-key')

IPCController.on('save-api-key')
â”œâ”€â”€ configurationManager.updateApiKey(apiKey) [âš¡]
â”‚   â”œâ”€â”€ validateApiKeyFormat(apiKey)
â”‚   â”‚   â”œâ”€â”€ checkApiKeyStructure() â†’ boolean
â”‚   â”‚   â””â”€â”€ â“ if (!valid) â†’ throw ValidationError
â”‚   â”œâ”€â”€ testApiKeyWithOpenAI(apiKey) [âš¡]
â”‚   â”‚   â”œâ”€â”€ testClient = new OpenAI({apiKey})
â”‚   â”‚   â”œâ”€â”€ testClient.models.list() [âš¡]
â”‚   â”‚   â””â”€â”€ â“ if (error) â†’ throw AuthenticationError
â”‚   â”œâ”€â”€ ğŸ’¾ storeApiKeySecurely(apiKey)
â”‚   â”‚   â”œâ”€â”€ â“ if (safeStorage.isEncryptionAvailable())
â”‚   â”‚   â”‚   â”œâ”€â”€ encryptedKey = safeStorage.encryptString(apiKey)
â”‚   â”‚   â”‚   â””â”€â”€ store.set('encrypted-api-key', encryptedKey)
â”‚   â”‚   â””â”€â”€ âŒ else â†’ store.set('api-key', apiKey)
â”‚   â”œâ”€â”€ updateOpenAIClient()
â”‚   â”‚   â””â”€â”€ this.openai = new OpenAI({apiKey})
â”‚   â””â”€â”€ âœ… configuration updated
â””â”€â”€ ğŸ¯ event.reply('api-key-saved')

Settings Window: Test API key
â”œâ”€â”€ ğŸ¯ ipcRenderer.send('test-api-key', apiKey)
â””â”€â”€ IPCController.on('test-api-key')

IPCController.on('test-api-key')
â”œâ”€â”€ createTestClient(apiKey) â†’ testOpenAI
â”œâ”€â”€ performAPITest() [âš¡]
â”‚   â”œâ”€â”€ testOpenAI.models.list() [âš¡]
â”‚   â”œâ”€â”€ âœ… validateResponse(response)
â”‚   â””â”€â”€ return {success: true}
â”œâ”€â”€ âš ï¸ catch (error) â†’ return {success: false, error}
â”œâ”€â”€ â“ if (testSuccessful)
â”‚   â””â”€â”€ ğŸ¯ event.reply('api-key-valid', 'API key is valid!')
â””â”€â”€ âŒ else
    â””â”€â”€ ğŸ¯ event.reply('api-key-invalid', error.message)
```

### 2. Configuration Loading

```
Application Startup: ConfigurationManager.initialize()
â”œâ”€â”€ loadConfigurationFile() [âš¡]
â”‚   â”œâ”€â”€ configPath = path.join(userData, 'config.json')
â”‚   â”œâ”€â”€ â“ if (!fs.existsSync(configPath)) â†’ createDefaultConfig()
â”‚   â”œâ”€â”€ rawConfig = fs.readFileSync(configPath, 'utf8')
â”‚   â”œâ”€â”€ ğŸ“ config = JSON.parse(rawConfig)
â”‚   â””â”€â”€ return config
â”œâ”€â”€ validateConfiguration(config)
â”‚   â”œâ”€â”€ checkRequiredFields(config)
â”‚   â”œâ”€â”€ validateApiKeyIfPresent(config.apiKey)
â”‚   â”œâ”€â”€ validateAudioDeviceIds(config.audioDevices)
â”‚   â””â”€â”€ â“ if (!valid) â†’ throw ConfigurationError
â”œâ”€â”€ loadApiKeyFromStorage()
â”‚   â”œâ”€â”€ â“ if (config.encryptedApiKey)
â”‚   â”‚   â”œâ”€â”€ decryptedKey = safeStorage.decryptString(config.encryptedApiKey)
â”‚   â”‚   â””â”€â”€ this.apiKey = decryptedKey
â”‚   â””â”€â”€ âŒ else if (config.apiKey) â†’ this.apiKey = config.apiKey
â”œâ”€â”€ initializeDefaults()
â”‚   â”œâ”€â”€ audioDevices = detectAudioDevices()
â”‚   â”œâ”€â”€ ocrLanguage = 'eng'
â”‚   â”œâ”€â”€ logLevel = 'info'
â”‚   â””â”€â”€ stealthMode = true
â””â”€â”€ ğŸ’¾ persistConfiguration()
```

---

## Error Handling Flow

### 1. Service Error Handling

```
Any Service Method Call
â”œâ”€â”€ try {
â”‚   â”œâ”€â”€ validateParameters()
â”‚   â”œâ”€â”€ checkServiceReady()
â”‚   â”œâ”€â”€ performOperation() [âš¡]
â”‚   â””â”€â”€ return result
â”‚   }
â”œâ”€â”€ catch (ServiceNotReadyError) {
â”‚   â”œâ”€â”€ logError('Service not initialized')
â”‚   â”œâ”€â”€ â“ attemptAutoInitialization()
â”‚   â””â”€â”€ âŒ throw new Error('Service unavailable')
â”‚   }
â”œâ”€â”€ catch (APIKeyNotConfiguredError) {
â”‚   â”œâ”€â”€ logError('OpenAI API key not configured')
â”‚   â”œâ”€â”€ generateFallbackResponse()
â”‚   â””â”€â”€ notifyUserToConfigureAPI()
â”‚   }
â”œâ”€â”€ catch (NetworkError) {
â”‚   â”œâ”€â”€ logError('Network request failed')
â”‚   â”œâ”€â”€ â“ isRetryable(error) â†’ scheduleRetry()
â”‚   â””â”€â”€ âŒ fallback to offline mode
â”‚   }
â”œâ”€â”€ catch (ValidationError) {
â”‚   â”œâ”€â”€ logError('Invalid parameters provided')
â”‚   â”œâ”€â”€ sanitizeParameters()
â”‚   â””â”€â”€ â“ canRecover() â†’ retry with cleaned params
â”‚   }
â””â”€â”€ catch (UnexpectedError) {
    â”œâ”€â”€ logError('Unexpected error occurred', error.stack)
    â”œâ”€â”€ captureErrorContext()
    â”œâ”€â”€ notifyErrorToUser()
    â””â”€â”€ gracefulDegradation()
    }
```

### 2. IPC Error Handling

```
IPC Event Handler
â”œâ”€â”€ try {
â”‚   â”œâ”€â”€ validateEventData()
â”‚   â”œâ”€â”€ processRequest() [âš¡]
â”‚   â””â”€â”€ ğŸ¯ event.reply('success', result)
â”‚   }
â”œâ”€â”€ catch (error) {
â”‚   â”œâ”€â”€ logError('IPC handler failed', {event, error})
â”‚   â”œâ”€â”€ categorizeError(error)
â”‚   â”‚   â”œâ”€â”€ ValidationError â†’ userFriendlyMessage
â”‚   â”‚   â”œâ”€â”€ ServiceError â†’ serviceUnavailableMessage
â”‚   â”‚   â””â”€â”€ UnknownError â†’ genericErrorMessage
â”‚   â””â”€â”€ ğŸ¯ event.reply('error', {
â”‚       type: errorType,
â”‚       message: userMessage,
â”‚       technical: error.message
â”‚       })
â”‚   }
â””â”€â”€ finally {
    â””â”€â”€ cleanupResources()
    }
```

---

## Data Persistence Flow

### 1. Session Data Persistence

```
Session State Changes
â”œâ”€â”€ sessionManager.persistSession(session) [âš¡]
â”‚   â”œâ”€â”€ sessionPath = path.join(userDataDir, 'sessions', `${sessionId}.json`)
â”‚   â”œâ”€â”€ sessionData = {
â”‚   â”‚   id: session.id,
â”‚   â”‚   profession: session.profession,
â”‚   â”‚   interviewType: session.interviewType,
â”‚   â”‚   context: session.context,
â”‚   â”‚   createdAt: session.createdAt,
â”‚   â”‚   isActive: session.isActive,
â”‚   â”‚   chatHistory: session.chatHistory,
â”‚   â”‚   metadata: session.metadata
â”‚   â”‚   }
â”‚   â”œâ”€â”€ ensureDirectoryExists(sessionsDir)
â”‚   â”œâ”€â”€ ğŸ’¾ fs.writeFileSync(sessionPath, JSON.stringify(sessionData, null, 2))
â”‚   â””â”€â”€ âœ… session persisted
â”œâ”€â”€ sessionManager.loadSession(sessionId) [âš¡]
â”‚   â”œâ”€â”€ sessionPath = path.join(userDataDir, 'sessions', `${sessionId}.json`)
â”‚   â”œâ”€â”€ â“ if (!fs.existsSync(sessionPath)) â†’ return null
â”‚   â”œâ”€â”€ rawData = fs.readFileSync(sessionPath, 'utf8')
â”‚   â”œâ”€â”€ ğŸ“ sessionData = JSON.parse(rawData)
â”‚   â”œâ”€â”€ validateSessionData(sessionData)
â”‚   â””â”€â”€ return reconstructSession(sessionData)
â””â”€â”€ sessionManager.getAllSessions() [âš¡]
    â”œâ”€â”€ sessionsDir = path.join(userDataDir, 'sessions')
    â”œâ”€â”€ sessionFiles = fs.readdirSync(sessionsDir).filter('.json')
    â”œâ”€â”€ ğŸ”„ for each sessionFile:
    â”‚   â”œâ”€â”€ loadSession(sessionId)
    â”‚   â””â”€â”€ activeSessions.push(session)
    â””â”€â”€ return activeSessions
```

### 2. Configuration Persistence

```
Configuration Changes
â”œâ”€â”€ configurationManager.saveConfiguration(config) [âš¡]
â”‚   â”œâ”€â”€ configPath = path.join(userDataDir, 'config.json')
â”‚   â”œâ”€â”€ validateConfiguration(config)
â”‚   â”œâ”€â”€ ğŸ“ configData = {
â”‚   â”‚   version: CONFIG_VERSION,
â”‚   â”‚   stealthMode: config.stealthMode,
â”‚   â”‚   logLevel: config.logLevel,
â”‚   â”‚   audioDevices: config.audioDevices,
â”‚   â”‚   ocrLanguage: config.ocrLanguage,
â”‚   â”‚   lastUpdated: new Date().toISOString()
â”‚   â”‚   }
â”‚   â”œâ”€â”€ createBackup(configPath) â†’ backupPath
â”‚   â”œâ”€â”€ ğŸ’¾ fs.writeFileSync(configPath, JSON.stringify(configData, null, 2))
â”‚   â””â”€â”€ âœ… configuration saved
â”œâ”€â”€ configurationManager.loadConfiguration() [âš¡]
â”‚   â”œâ”€â”€ configPath = path.join(userDataDir, 'config.json')
â”‚   â”œâ”€â”€ â“ if (!fs.existsSync(configPath)) â†’ createDefaultConfiguration()
â”‚   â”œâ”€â”€ rawConfig = fs.readFileSync(configPath, 'utf8')
â”‚   â”œâ”€â”€ ğŸ“ config = JSON.parse(rawConfig)
â”‚   â”œâ”€â”€ migrateConfigurationIfNeeded(config)
â”‚   â”œâ”€â”€ validateConfiguration(config)
â”‚   â””â”€â”€ return config
â””â”€â”€ autoSaveConfiguration()
    â”œâ”€â”€ detectConfigurationChanges()
    â”œâ”€â”€ â“ if (changesDetected)
    â”‚   â”œâ”€â”€ debounce(saveConfiguration, 1000)
    â”‚   â””â”€â”€ logConfigurationChange()
    â””â”€â”€ scheduleNextCheck()
```

### 3. RAG Data Persistence

```
Knowledge Base Operations
â”œâ”€â”€ globalRagService.persistVectorDatabase() [âš¡]
â”‚   â”œâ”€â”€ dbPath = path.join(userDataDir, 'vector-db')
â”‚   â”œâ”€â”€ ensureDirectoryExists(dbPath)
â”‚   â”œâ”€â”€ lanceDB.save(dbPath) [âš¡]
â”‚   â”œâ”€â”€ generateDatabaseMetadata()
â”‚   â”‚   â”œâ”€â”€ totalDocuments = countDocuments()
â”‚   â”‚   â”œâ”€â”€ totalChunks = countChunks()
â”‚   â”‚   â”œâ”€â”€ databaseSize = calculateSize()
â”‚   â”‚   â””â”€â”€ lastUpdate = new Date()
â”‚   â”œâ”€â”€ ğŸ’¾ saveMetadata(metadata)
â”‚   â””â”€â”€ âœ… vector database persisted
â”œâ”€â”€ globalRagService.loadVectorDatabase() [âš¡]
â”‚   â”œâ”€â”€ dbPath = path.join(userDataDir, 'vector-db')
â”‚   â”œâ”€â”€ â“ if (!fs.existsSync(dbPath)) â†’ initializeEmptyDatabase()
â”‚   â”œâ”€â”€ lanceDB.load(dbPath) [âš¡]
â”‚   â”œâ”€â”€ loadDatabaseMetadata()
â”‚   â”œâ”€â”€ validateDatabaseIntegrity()
â”‚   â””â”€â”€ âœ… vector database loaded
â””â”€â”€ cleanupOldData()
    â”œâ”€â”€ findExpiredSessions() â†’ oldSessionIds[]
    â”œâ”€â”€ ğŸ”„ for each oldSessionId:
    â”‚   â”œâ”€â”€ removeSessionVectorData(oldSessionId)
    â”‚   â”œâ”€â”€ deleteSessionFiles(oldSessionId)
    â”‚   â””â”€â”€ cleanupCount++
    â””â”€â”€ logCleanupResults(cleanupCount)
```

---

This comprehensive flow documentation shows the exact sequence of function calls, data transformations, and system interactions for all major application flows in GhostGuide.
